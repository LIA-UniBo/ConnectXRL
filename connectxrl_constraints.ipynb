{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "connectxrl_constraints.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba66idGhR18B"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u4u40cLi3T5"
      },
      "source": [
        "# !rm -rf ConnectXRL/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YayXzhljIyP"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlW2Dywip1_-"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = 'alomb'\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password)\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, 'ConnectXRL')\n",
        "\n",
        "os.system(cmd_string)\n",
        "del cmd_string\n",
        "del password"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MclgkwjRskWd"
      },
      "source": [
        "!pip install kaggle-environments webcolors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsZPvV-UpoIa"
      },
      "source": [
        "sys.path.append('ConnectXRL')\n",
        "sys.path.append('ConnectXRL/src')\n",
        "sys.path.append('ConnectXRL/src/connectx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLBfeJaFP1az"
      },
      "source": [
        "from random import choice\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from kaggle_environments import make, evaluate\n",
        "\n",
        "from src.connectx.constraints import ConstraintType, Constraints\n",
        "from src.connectx.environment import ConnectXGymEnv, convert_state_to_image\n",
        "from src.connectx.evaluate import get_win_percentages\n",
        "from policy import CNNPolicy\n",
        "from dqn import DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cutclmjRSH4F"
      },
      "source": [
        "Define configurations of the game"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keU1FGLTSHjp"
      },
      "source": [
        "# ----\n",
        "# Game\n",
        "# ----\n",
        "BOARD_COLUMNS = 7\n",
        "BOARD_ROWS = 6\n",
        "STONES_TO_WIN = 4\n",
        "\n",
        "# --------\n",
        "# Training\n",
        "# --------\n",
        "# Rewards\n",
        "INVALID_REWARD = -1.0\n",
        "VICTORY_REWARD = 1.0\n",
        "LOST_REWARD = -1.0\n",
        "DRAW_REWARD = 0.5\n",
        "\n",
        "PLAYER_2ND_EPISODES = 2\n",
        "PLAYER_1ST_EPISODES = 2\n",
        "SAVE_FREQ = PLAYER_1ST_EPISODES + PLAYER_2ND_EPISODES\n",
        "\n",
        "# Rendering\n",
        "RENDER_ENV = False\n",
        "RENDER_WAITING_TIME = 1\n",
        "UPDATE_PLOT_FREQ = 100\n",
        "REWARD_AVG_ROLL_WINDOW_SIZE = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gb5fgqVRJQ8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwPXdFp8RXi7"
      },
      "source": [
        "Define all the different agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laE9IkZRQTR5"
      },
      "source": [
        "agents = {\n",
        "    'DQN': {\n",
        "        'constraint_type': None,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'train_opponent': 'random',\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './dqn/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "    'LOGIC_PURE': {\n",
        "        'constraint_type': ConstraintType.LOGIC_PURE,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'train_opponent': 'random',\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './logic_pure/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "    'LOGIC_TRAIN': {\n",
        "        'constraint_type': ConstraintType.LOGIC_TRAIN,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'train_opponent': 'random',\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './logic_train/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "    'SPE': {\n",
        "        'constraint_type': ConstraintType.SPE,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'train_opponent': 'random',\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './spe/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "    'SBR': {\n",
        "        'constraint_type': ConstraintType.SBR,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'train_opponent': 'random',\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './sbr/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "    'CDQN': {\n",
        "        'constraint_type': ConstraintType.CDQN,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'train_opponent': 'random',\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './cdqn/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yquKq4TUQztg"
      },
      "source": [
        "# Create weights folders\n",
        "for a in agents.values():\n",
        "    if not os.path.isdir(a['train_weights_path']):\n",
        "        os.mkdir(a['train_weights_path'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsmxyZnvRhM5"
      },
      "source": [
        "Train agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUZBCeu1Ri1Z"
      },
      "source": [
        "for a in agents.values():\n",
        "    env = ConnectXGymEnv(a['train_opponent'],\n",
        "                         first=True,\n",
        "                         invalid_reward=INVALID_REWARD,\n",
        "                         victory_reward=VICTORY_REWARD,\n",
        "                         lost_reward=LOST_REWARD,\n",
        "                         draw_reward=DRAW_REWARD)\n",
        "\n",
        "    dqn = DQN(env,\n",
        "              non_local=a['non_local'],\n",
        "              batch_size=128,\n",
        "              gamma=0.99,\n",
        "              eps_start=1.0,\n",
        "              eps_end=0.01,\n",
        "              eps_decay=10000,\n",
        "              memory_size=10000,\n",
        "              target_update=500,\n",
        "              learning_rate=1e-2,\n",
        "              epochs=2,\n",
        "              constraint_type=a['constraint_type'],\n",
        "              device='cuda',\n",
        "              notebook=True)\n",
        "\n",
        "    dqn.training_loop(a['n_episodes_as_1st_player'],\n",
        "                      a['n_episodes_as_2nd_player'],\n",
        "                      save_path=a['train_weights_path'],\n",
        "                      save_frequency=a['train_save_freq'],\n",
        "                      render_env=RENDER_ENV,\n",
        "                      render_waiting_time=RENDER_WAITING_TIME,\n",
        "                      update_plots_frequency=UPDATE_PLOT_FREQ,\n",
        "                      plot_duration=True,\n",
        "                      plot_mean_reward=True,\n",
        "                      plot_actions_count=True,\n",
        "                      cumulative_reward_avg_roll_window=REWARD_AVG_ROLL_WINDOW_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcec3ezTRVj9"
      },
      "source": [
        "Initialize the models for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjMK2oAuREL5"
      },
      "source": [
        "for a in agents.values():\n",
        "    a['model'] = CNNPolicy(BOARD_COLUMNS,\n",
        "                           (3, BOARD_ROWS, BOARD_COLUMNS),\n",
        "                           non_local=a['non_local'])\n",
        "    a['model'].load_state_dict(torch.load(a['train_weights_path'] +\n",
        "                                          'weights_' +\n",
        "                                          str(a['test_weights']) +\n",
        "                                          '.pt'))\n",
        "    a['model'].eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CBRjpYfR0Yk"
      },
      "source": [
        "Test agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr7aeOCCQDRF"
      },
      "source": [
        "show_percentages = True\n",
        "\n",
        "for a, a_c in agents.items():\n",
        "    for e in range(1):\n",
        "        print(f'{e}) Evaluating agent {a}:')\n",
        "\n",
        "        # Define function used to represent the agent at testing time\n",
        "        def dqn_agent(observation: dict,\n",
        "                      configuration: dict) -> int:\n",
        "            \"\"\"\n",
        "            Agent trained using DQN and trained on the images of the game.\n",
        "\n",
        "            :param observation: turn's data (board status, step number, ...)\n",
        "            :param configuration: environment's data (steps, board, timeouts, ...) and weights file path\n",
        "            :return: the column where the stone is inserted\n",
        "            \"\"\"\n",
        "\n",
        "            # print(observation)\n",
        "            # print(configuration)\n",
        "\n",
        "            c_type = a_c['constraint_type']\n",
        "            constraints = Constraints(c_type, observation.mark) if c_type else None\n",
        "\n",
        "            col = None\n",
        "            board = np.array(observation.board).reshape(BOARD_ROWS, BOARD_COLUMNS, 1)\n",
        "\n",
        "            # If LOGIC_PURE detect a critical situation the correct action is performed\n",
        "            if constraints and c_type is ConstraintType.LOGIC_PURE:\n",
        "                col = constraints.select_constrained_action(board.squeeze()).unsqueeze(0)\n",
        "\n",
        "            if constraints is None or \\\n",
        "                    col is None or \\\n",
        "                    (col.sum().item() != 1 and c_type is ConstraintType.LOGIC_PURE):\n",
        "\n",
        "                col = a_c['model'](torch.from_numpy(convert_state_to_image(board)))\n",
        "\n",
        "                # Safe policy estimation on the action values\n",
        "                if constraints and c_type is ConstraintType.SPE:\n",
        "                    # Compute action masks\n",
        "                    constraints = constraints.select_constrained_action(board.squeeze())\n",
        "                    # Set invalid actions to -inf\n",
        "                    col.squeeze()[constraints == 0] = -np.inf\n",
        "\n",
        "            if type(col) is not int:\n",
        "                # Select action suggested by constraints\n",
        "                col = col.max(1)[1].item()\n",
        "\n",
        "            # Check if selected column is valid\n",
        "            is_valid = (observation.board[col] == 0)\n",
        "\n",
        "            # If not valid, select random move\n",
        "            if is_valid:\n",
        "                return col\n",
        "            else:\n",
        "                return choice([c for c in range(configuration.columns) if observation.board[c] == 0])\n",
        "\n",
        "        env = make('connectx', debug=True)\n",
        "        print(f'{list(env.agents)[0]} VS {list(env.agents)[1]}')\n",
        "\n",
        "        if not show_percentages:\n",
        "            env.run([dqn_agent, a_c['test_opponent']])\n",
        "            env.render(mode = 'ipython')\n",
        "        else:\n",
        "            get_win_percentages(dqn_agent,\n",
        "                                ['random', 'negamax'],\n",
        "                                player_name=a_c['constraint_type'],\n",
        "                                n_rounds_as_1st_player=30,\n",
        "                                n_rounds_as_2nd_player=30)\n",
        "\n",
        "        print('='* 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR3n-c6zqkID"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}