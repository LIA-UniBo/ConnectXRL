{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "connectxrl_constraints.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba66idGhR18B"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u4u40cLi3T5"
      },
      "source": [
        "# !rm -rf ConnectXRL/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YayXzhljIyP"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlW2Dywip1_-"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = 'FiorenzoParascandolo1'\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password)\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/alomb/{2}.git'.format(user, password, 'ConnectXRL')\n",
        "\n",
        "os.system(cmd_string)\n",
        "del cmd_string\n",
        "del password"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MclgkwjRskWd"
      },
      "source": [
        "!pip install kaggle-environments webcolors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsZPvV-UpoIa"
      },
      "source": [
        "sys.path.append('ConnectXRL')\n",
        "sys.path.append('ConnectXRL/src')\n",
        "sys.path.append('ConnectXRL/src/connectx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLBfeJaFP1az"
      },
      "source": [
        "from random import choice\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from kaggle_environments import make, evaluate\n",
        "\n",
        "from src.connectx.constraints import ConstraintType, Constraints\n",
        "from src.connectx.environment import ConnectXGymEnv, convert_state_to_image\n",
        "from src.connectx.evaluate import get_win_percentages, fix_random\n",
        "from policy import CNNPolicy\n",
        "from dqn import DQN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cutclmjRSH4F"
      },
      "source": [
        "Define configurations of the game"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pMuTlcUGp3f"
      },
      "source": [
        "fix_random(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keU1FGLTSHjp"
      },
      "source": [
        "# ----\n",
        "# Game\n",
        "# ----\n",
        "BOARD_COLUMNS = 7\n",
        "BOARD_ROWS = 6\n",
        "STONES_TO_WIN = 4\n",
        "\n",
        "# --------\n",
        "# Training\n",
        "# --------\n",
        "# Rewards\n",
        "INVALID_REWARD = -1.0\n",
        "VICTORY_REWARD = 1.0\n",
        "LOST_REWARD = -1.0\n",
        "DRAW_REWARD = 0.0\n",
        "\n",
        "PLAYER_2ND_EPISODES = 1250\n",
        "PLAYER_1ST_EPISODES = 1250\n",
        "SAVE_FREQ = PLAYER_1ST_EPISODES + PLAYER_2ND_EPISODES\n",
        "\n",
        "# Rendering\n",
        "RENDER_ENV = False\n",
        "RENDER_WAITING_TIME = 1\n",
        "UPDATE_PLOT_FREQ = 100\n",
        "REWARD_AVG_ROLL_WINDOW_SIZE = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwPXdFp8RXi7"
      },
      "source": [
        "Define all the different agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laE9IkZRQTR5"
      },
      "source": [
        "agents = {\n",
        "    'DQN': {\n",
        "        'constraint_type': None,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './dqn/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "    'LOGIC_PURE': {\n",
        "        'constraint_type': ConstraintType.LOGIC_PURE,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './logic_pure/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "    'LOGIC_TRAIN': {\n",
        "        'constraint_type': ConstraintType.LOGIC_TRAIN,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './logic_train/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "    'SPE': {\n",
        "        'constraint_type': ConstraintType.SPE,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './spe/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "    'SBR': {\n",
        "        'constraint_type': ConstraintType.SBR,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './sbr/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "    'CDQN': {\n",
        "        'constraint_type': ConstraintType.CDQN,\n",
        "        'non_local': False,\n",
        "        'train_first_player': True,\n",
        "        'n_episodes_as_1st_player': PLAYER_1ST_EPISODES,\n",
        "        'n_episodes_as_2nd_player': PLAYER_2ND_EPISODES,\n",
        "        'train_save_freq': SAVE_FREQ, \n",
        "        'train_weights_path': './cdqn/',\n",
        "        'test_weights': SAVE_FREQ,\n",
        "        'test_opponent': 'negamax',\n",
        "    },\n",
        "}\n",
        "\n",
        "train_opponents = {0: ('random', 0.99),\n",
        "                   1: ('negamax', 0.01)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7rc3Ev2xk3r"
      },
      "source": [
        "# Remove weights folders\n",
        "import shutil\n",
        "\n",
        "for a in agents.values():\n",
        "    if os.path.isdir(a['train_weights_path']):\n",
        "        shutil.rmtree(a['train_weights_path'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yquKq4TUQztg"
      },
      "source": [
        "# Create weights folders\n",
        "for a in agents.values():\n",
        "    if not os.path.isdir(a['train_weights_path']):\n",
        "        os.mkdir(a['train_weights_path'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsmxyZnvRhM5"
      },
      "source": [
        "Train agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUZBCeu1Ri1Z"
      },
      "source": [
        "for a in agents.values():\n",
        "    for i in train_opponents.keys():\n",
        "        env = ConnectXGymEnv(train_opponents[i][0],\n",
        "                             first=True,\n",
        "                             invalid_reward=INVALID_REWARD,\n",
        "                             victory_reward=VICTORY_REWARD,\n",
        "                             lost_reward=LOST_REWARD,\n",
        "                             draw_reward=DRAW_REWARD)\n",
        "\n",
        "        dqn = DQN(env,\n",
        "                  non_local=a['non_local'],\n",
        "                  batch_size=8,\n",
        "                  gamma=0.99,\n",
        "                  eps_start=train_opponents[i][1],\n",
        "                  eps_end=0.01,\n",
        "                  eps_decay=1000,\n",
        "                  memory_size=1024,\n",
        "                  target_update=10,\n",
        "                  learning_rate=1e-4,\n",
        "                  epochs=1,\n",
        "                  constraint_type=a['constraint_type'],\n",
        "                  device='cpu',\n",
        "                  notebook=True)\n",
        "        \n",
        "        if os.listdir(a['train_weights_path']) != []:\n",
        "            dqn.policy_net.load_state_dict(torch.load(a['train_weights_path'] +\n",
        "                                          'weights_' +\n",
        "                                          str(a['test_weights']) +\n",
        "                                          '.pt'))\n",
        "            dqn.policy_net.load_state_dict(torch.load(a['train_weights_path'] +\n",
        "                                'weights_' +\n",
        "                                str(a['test_weights']) +\n",
        "                                '.pt'))\n",
        "            \n",
        "        dqn.training_loop(a['n_episodes_as_1st_player'],\n",
        "                          a['n_episodes_as_2nd_player'],\n",
        "                          save_path=a['train_weights_path'],\n",
        "                          save_frequency=a['train_save_freq'],\n",
        "                          render_env=RENDER_ENV,\n",
        "                          render_waiting_time=RENDER_WAITING_TIME,\n",
        "                          update_plots_frequency=UPDATE_PLOT_FREQ,\n",
        "                          plot_duration=True,\n",
        "                          plot_mean_reward=True,\n",
        "                          plot_actions_count=True,\n",
        "                          avg_roll_window=REWARD_AVG_ROLL_WINDOW_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcec3ezTRVj9"
      },
      "source": [
        "Initialize the models for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjMK2oAuREL5"
      },
      "source": [
        "for a in agents.values():\n",
        "    a['model'] = CNNPolicy(BOARD_COLUMNS,\n",
        "                           (3, BOARD_ROWS, BOARD_COLUMNS),\n",
        "                           non_local=a['non_local'])\n",
        "    a['model'].load_state_dict(torch.load(a['train_weights_path'] +\n",
        "                                          'weights_' +\n",
        "                                          str(a['test_weights']) +\n",
        "                                          '.pt'))\n",
        "    # a['model'].eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CBRjpYfR0Yk"
      },
      "source": [
        "Test agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr7aeOCCQDRF"
      },
      "source": [
        "show_percentages = True\n",
        "\n",
        "for a, a_c in agents.items():\n",
        "    for e in range(1):\n",
        "        print(f'{e}) Evaluating agent {a}:')\n",
        "\n",
        "        # Define function used to represent the agent at testing time\n",
        "        def dqn_agent(observation: dict,\n",
        "                     configuration: dict) -> int:\n",
        "            \"\"\"\n",
        "            Agent trained using DQN and trained on the images of the game.\n",
        "\n",
        "            :param observation: turn's data (board status, step number, ...)\n",
        "            :param configuration: environment's data (steps, board, timeouts, ...) and weights file path\n",
        "            :return: the column where the stone is inserted\n",
        "            \"\"\"\n",
        "\n",
        "            # print(observation)\n",
        "            # print(configuration)\n",
        "            configuration['c_type'] = a_c['constraint_type']\n",
        "            return a_c['model'].predict(observation=observation, configuration=configuration)\n",
        "\n",
        "        env = make('connectx', debug=True)\n",
        "        print(f'{list(env.agents)[0]} VS {list(env.agents)[1]}')\n",
        "\n",
        "        if not show_percentages:\n",
        "            env.run([dqn_agent, a_c['test_opponent']])\n",
        "            env.render(mode = 'ipython')\n",
        "        else:\n",
        "            get_win_percentages(dqn_agent,\n",
        "                                ['random', 'negamax'],\n",
        "                                player_name=a_c['constraint_type'],\n",
        "                                n_rounds_as_1st_player=30,\n",
        "                                n_rounds_as_2nd_player=30)\n",
        "\n",
        "        print('='* 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR3n-c6zqkID"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}